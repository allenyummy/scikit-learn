{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import argparse\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DataReader Class\n",
    "The DataReader can read train_valid_file and test_file with selected features and an ouptut.\n",
    "The format of file must be an excel file. If you want to make csv file compatible with datareader, {pd.read_csv} is suggested to be replace with {pd.read_excel}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataReader():\n",
    "    def __init__(self, data_dir, train_valid_file, test_file, feature_in, output_col, k_fold):\n",
    "        self.data_dir = data_dir \n",
    "        self.train_valid_file = os.path.join(data_dir, train_valid_file)\n",
    "        self.test_file = os.path.join(data_dir, test_file)\n",
    "        ## selected features, a string list is requested. \n",
    "        ## If you create datareader object on your own, a string list is requested, like ['A1','A2'.'A3'].\n",
    "        ## If you run the scripts of run_knn.sh, a string with space is requested, like \"A1 A2 A3\".\n",
    "        self.feature_in = feature_in  \n",
    "        ## selecetd output columns, a string is requested.\n",
    "        self.output_col = output_col\n",
    "        self.k_fold = k_fold\n",
    "        self.usecols = feature_in + [output_col]\n",
    "        \n",
    "    def get_train_valid_data(self, is_shuffle, split_ratio):\n",
    "        train_valid_data = pd.read_excel(self.train_valid_file, usecols=self.usecols)\n",
    "        ## Classification Type of t.rain_valid_data is ascending. \n",
    "        ## It will cause unbalenced data when we split it into training set and validation set without shuffling it.\n",
    "        if is_shuffle:\n",
    "            train_valid_data = shuffle(train_valid_data, random_state=0)\n",
    "            train_valid_data.index = range(len(train_valid_data))\n",
    "        \n",
    "        ## This means k_fold validation don't work,\n",
    "        ## so the split ratio is requested to be split train_valid_data into training set and valid set.\n",
    "        if self.k_fold == 1:\n",
    "            split_idx = int(train_valid_data.shape[0]*split_ratio)\n",
    "            train_data, valid_data = train_valid_data[:split_idx], train_valid_data[split_idx:]\n",
    "            train_x, train_y = train_data[self.feature_in], train_data[self.output_col]\n",
    "            valid_x, valid_y = valid_data[self.feature_in], valid_data[self.output_col]\n",
    "            return train_valid_data, train_data, train_x, train_y, valid_data, valid_x, valid_y \n",
    "        \n",
    "        ## This means k_fold validation works. It returns the shuffle data and the split index.\n",
    "        elif self.k_fold > 1:\n",
    "            kf = KFold(n_splits=self.k_fold)\n",
    "            return train_valid_data, kf.split(train_valid_data)\n",
    "                \n",
    "    def get_test_data(self):\n",
    "        test_data = pd.read_excel(self.test_file, usecols=self.usecols)\n",
    "        test_x, test_y = test_data[self.feature_in], test_data[self.output_col]\n",
    "        return test_data, test_x, test_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNearestNeighbor Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNN():\n",
    "    def __init__(self, n_neighbors, weights, power_param):\n",
    "        self.n_neighbors = n_neighbors\n",
    "        self.weights = weights\n",
    "        self.power_param = power_param        \n",
    "        self.knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights, p=power_param)\n",
    "        \n",
    "    def train(self, data_x, data_y): \n",
    "        return self.knn.fit(data_x, data_y) \n",
    "    \n",
    "    ## it returns accuracy score\n",
    "    def evaluate(self, data_x, data_y):\n",
    "        return self.knn.score(data_x, data_y)\n",
    "    \n",
    "    def predict(self, data_x):\n",
    "        return self.knn.predict(data_x)\n",
    "    \n",
    "    @staticmethod\n",
    "    def classification_report(y_true, y_pred):        \n",
    "        ## Number of digits for formatting output floating point values. \n",
    "        ## When output_dict is True, this will be ignored and the returned values will not be rounded.\n",
    "        print (classification_report(y_true, y_pred, digits=4))        ## for terminal look\n",
    "        return classification_report(y_true, y_pred, output_dict=True) ## for report   \n",
    "        \n",
    "    @staticmethod\n",
    "    def confusion_matrix(y_true, y_pred, labels):\n",
    "        def cm2pd(cm, labels):            \n",
    "            cm_df = pd.DataFrame(index=labels)\n",
    "            for idx, label in enumerate(labels):\n",
    "                cm_df[f'pred_{label}'] = cm[:, idx]\n",
    "            return cm_df\n",
    "        cm = confusion_matrix(y_true, y_pred)\n",
    "        print(cm)\n",
    "        cm_df = cm2pd(cm, labels)\n",
    "        return cm_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without K fold validation (k = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def no_k_fold(datareader, knn, output_dir):\n",
    "    \n",
    "    ## data preparation\n",
    "    train_valid_data, \\\n",
    "    train_data, train_x, train_y, \\\n",
    "    valid_data, valid_x, valid_y = datareader.get_train_valid_data(is_shuffle=True, split_ratio=0.7)       \n",
    "    test_data, test_x, test_y = datareader.get_test_data()       \n",
    "    \n",
    "    ## classification\n",
    "    ## train knn\n",
    "    knn.train(train_x, train_y)\n",
    "    with open(output_dir+'/knn.pickle', 'wb') as f:\n",
    "        pickle.dump(knn, f)\n",
    "    \n",
    "    ## predict \n",
    "    train_y_pred = knn.predict(train_x)\n",
    "    valid_y_pred = knn.predict(valid_x)\n",
    "    test_y_pred = knn.predict(test_x)                \n",
    "        \n",
    "    ## evaluate\n",
    "    print ('###################')\n",
    "    print ('#### train set ####')\n",
    "    print ('###################')\n",
    "    train_report = knn.classification_report(train_y, train_y_pred)\n",
    "    train_labels = [*train_report][:-3]\n",
    "    train_report = pd.DataFrame(train_report).transpose()    \n",
    "    train_cm_df  = knn.confusion_matrix(train_y, train_y_pred, train_labels)    \n",
    "    print ()\n",
    "    \n",
    "    print ('###################')\n",
    "    print ('#### valid set ####')\n",
    "    print ('###################')\n",
    "    valid_report = knn.classification_report(valid_y, valid_y_pred) \n",
    "    valid_labels = [*valid_report][:-3]\n",
    "    valid_report = pd.DataFrame(valid_report).transpose()\n",
    "    valid_cm_df = knn.confusion_matrix(valid_y, valid_y_pred, valid_labels)\n",
    "    print ()\n",
    "    \n",
    "    print ('##################')\n",
    "    print ('#### test set ####')\n",
    "    print ('##################')\n",
    "    test_report = knn.classification_report(test_y, test_y_pred)\n",
    "    test_labels = [*test_report][:-3]\n",
    "    test_report = pd.DataFrame(test_report).transpose()\n",
    "    test_cm_df = knn.confusion_matrix(test_y, test_y_pred, test_labels)\n",
    "    \n",
    "    ## report to excel file\n",
    "    with pd.ExcelWriter(output_dir+'/result.xlsx') as writer:   \n",
    "        train_data.insert(len(datareader.usecols), 'pred_Type', train_y_pred)        \n",
    "        train_data.to_excel(writer, sheet_name='train_data')        \n",
    "        train_report.to_excel(writer, sheet_name='train_report')\n",
    "        train_cm_df.to_excel(writer, sheet_name='train_cm')\n",
    "        \n",
    "        valid_data.insert(len(datareader.usecols), 'pred_Type', valid_y_pred)\n",
    "        valid_data.to_excel(writer, sheet_name='valid_data')\n",
    "        valid_report.to_excel(writer, sheet_name='valid_report')\n",
    "        valid_cm_df.to_excel(writer, sheet_name='valid_cm')\n",
    "        \n",
    "        test_data.insert(len(datareader.usecols), 'pred_Type', test_y_pred)\n",
    "        test_data.to_excel(writer, sheet_name='test_data')\n",
    "        test_report.to_excel(writer, sheet_name='test_report')\n",
    "        test_cm_df.to_excel(writer, sheet_name='test_cm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With K Fold validation (k > 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold_validation(datareader, knn, output_dir):\n",
    "    \n",
    "    ## data preparation\n",
    "    train_valid_data, kf = datareader.get_train_valid_data(is_shuffle=True, split_ratio=None)       \n",
    "    test_data, test_x, test_y = datareader.get_test_data()\n",
    "    \n",
    "    result = pd.DataFrame()\n",
    "    ## k-fold validation\n",
    "    for i, (train_idx, valid_idx) in enumerate(kf):\n",
    "        train_data, valid_data = train_valid_data.iloc[train_idx], train_valid_data.iloc[valid_idx]\n",
    "        train_x, train_y = train_data[datareader.feature_in], train_data[datareader.output_col]\n",
    "        valid_x, valid_y = valid_data[datareader.feature_in], valid_data[datareader.output_col]\n",
    "        \n",
    "        ## classification\n",
    "        ## train knn\n",
    "        knn.train(train_x, train_y)                \n",
    "        \n",
    "        ## evaluate\n",
    "        acc_train = knn.evaluate(train_x, train_y) \n",
    "        acc_valid = knn.evaluate(valid_x, valid_y) \n",
    "        acc_test = knn.evaluate(test_x, test_y) \n",
    "        \n",
    "#         train_report = knn.classification_report(train_y, train_y_pred)\n",
    "#         train_report = pd.DataFrame(train_report).transpose()\n",
    "#         valid_report = knn.classification_report(valid_y, valid_y_pred) \n",
    "#         valid_report = pd.DataFrame(valid_report).transpose()\n",
    "#         test_report = knn.classification_report(test_y, test_y_pred)\n",
    "#         test_report = pd.DataFrame(test_report).transpose()\n",
    "#         print (f\"precision: {train_report.loc['weighted avg', 'precision']}\")\n",
    "#         print (f\"precision: {train_report.loc['weighted avg', 'recall']}\")\n",
    "#         print (f\"precision: {train_report.loc['weighted avg', 'f1-score']}\")\n",
    "        \n",
    "        result.loc[i, 'k_fold'] = str(i+1)\n",
    "        result.loc[i, 'train'] = acc_train\n",
    "        result.loc[i, 'valid'] = acc_valid\n",
    "        result.loc[i, 'test'] = acc_test\n",
    "    \n",
    "    ## report to excel file\n",
    "    result.loc[i+1, 'k_fold'] = 'avg'\n",
    "    result.loc[i+1, 'train'] = np.mean(result['train'][:i+1])\n",
    "    result.loc[i+1, 'valid'] = np.mean(result['valid'][:i+1])\n",
    "    result.loc[i+1, 'test'] = np.mean(result['test'][:i+1])\n",
    "    #print (result)\n",
    "    with pd.ExcelWriter(output_dir+'/result.xlsx') as writer:           \n",
    "        result.to_excel(writer, sheet_name='accuracy_report') \n",
    "    \n",
    "    return result.loc[i+1,'train'], result.loc[i+1,'valid'], result.loc[i+1,'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration func. for args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configuration(args):\n",
    "    config = {\n",
    "        'data_dir': args.data_dir,\n",
    "        'train_valid_file': args.train_valid_file,\n",
    "        'test_file': args.test_file,\n",
    "        'feature_input': args.feature_in,\n",
    "        'output_column': args.output_col,\n",
    "        'is_shuffle': args.is_shuffle,\n",
    "        'k_fold': args.k_fold,  \n",
    "        'n_neighbors': args.n_neighbors,\n",
    "        'weights': args.weights,\n",
    "        'power_param': args.power_param}        \n",
    "    return config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration func. for grid search.ipynb or any program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def configuration_grid_search(datareader, knn):\n",
    "    config = {\n",
    "        'data_dir': datareader.data_dir,\n",
    "        'train_valid_file': datareader.train_valid_file,\n",
    "        'test_file': datareader.test_file,\n",
    "        'feature_input': datareader.feature_in,\n",
    "        'output_column': datareader.output_col,\n",
    "        'is_shuffle': True,\n",
    "        'k_fold': datareader.k_fold,  \n",
    "        'n_neighbors': knn.n_neighbors,\n",
    "        'weights': knn.weights,\n",
    "        'power_param': knn.power_param}        \n",
    "    return config"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
